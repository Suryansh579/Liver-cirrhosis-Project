import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score, confusion_matrix
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense
from imblearn.over_sampling import RandomOverSampler
from tensorflow.keras.utils import to_categorical


# Apply oversampling to balance the classes
ros = RandomOverSampler(random_state=42)
X_resampled, y_resampled = ros.fit_resample(X, y)

# Scale the features
scaler = StandardScaler()
X_resampled = scaler.fit_transform(X_resampled)

# Reshape data to fit into Conv1D input
X_reshaped = X_resampled.reshape((X_resampled.shape[0], X_resampled.shape[1], 1))

# One-hot encode the target variable
y_categorical = to_categorical(y_resampled)

# Define CNN model function
def create_cnn_model(input_shape):
    model = Sequential()
    model.add(Conv1D(32, kernel_size=2, activation='relu', input_shape=input_shape))
    model.add(MaxPooling1D(pool_size=2))
    model.add(Flatten())
    model.add(Dense(10, activation='relu'))
    model.add(Dense(2, activation='softmax'))
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

# Define SVM model
svm_model = SVC(kernel='linear', random_state=42, probability=True)

kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
cv_accuracy = []

for train_index, test_index in kf.split(X_reshaped, y_resampled):
    X_train_val, X_test = X_reshaped[train_index], X_reshaped[test_index]
    y_train_val, y_test = y_categorical[train_index], y_categorical[test_index]
    
    val_split = int(0.8 * len(X_train_val))
    X_train, X_val = X_train_val[:val_split], X_train_val[val_split:]
    y_train, y_val = y_train_val[:val_split], y_train_val[val_split:]

    cnn_model = create_cnn_model((X_train.shape[1], 1))

    cnn_model.fit(X_train, y_train, epochs=150, batch_size=16, verbose=0)

    val_pred_probs = cnn_model.predict(X_val)

    # Check if y_val has more than one class
    if len(np.unique(np.argmax(y_val, axis=1))) > 1:
        # Train SVM on validation set predictions
        svm_model.fit(val_pred_probs, np.argmax(y_val, axis=1))

        # Evaluate the ensemble model on test set
        test_pred_probs = cnn_model.predict(X_test)
        y_pred = svm_model.predict(test_pred_probs)
        y_test_classes = np.argmax(y_test, axis=1)
        accuracy = accuracy_score(y_test_classes, y_pred)
        cv_accuracy.append(accuracy)

if cv_accuracy:
    print(f'Average Cross-Validation Accuracy of Ensemble Model: {np.mean(cv_accuracy):.4f}')
else:
    print("No valid folds were available for training the SVM model.")

cnn_model.fit(X_reshaped, y_categorical, epochs=150, batch_size=16)
cnn_pred_probs = cnn_model.predict(X_reshaped)
svm_model.fit(cnn_pred_probs, np.argmax(y_categorical, axis=1))

y_pred = svm_model.predict(cnn_model.predict(X_test))
y_test_classes = np.argmax(y_test, axis=1)

final_cm = confusion_matrix(y_test_classes, y_pred)
print("Confusion Matrix for Ensemble Model:")
print(final_cm)
print("classification report :")
print(classification_report(y_test_classes, y_pred))
